# Design Doc (RU)

# **Introduction**

Спам - это нежелательные электронные письма или списки рассылки, которые могут приходить на ваш адрес. Они могут содержать рекламные предложения, компьютерные вирусы или оказаться попыткой фишинга. Спам-сообщения в чатах telegram (далее - чаты) часто содержат рекламные предложения, реже вирусы и фишинг.
В этом документе описывается проект по созданию Telegram-бота (далее - бот), который будет автоматически блокировать пользователей, оставляющих спам-сообщения (далее - спам). В документе обсуждается формулировка задачи и целей проекта, определяются показатели и описываются методы сбора данных, анализа ошибок и этапы интеграции модели.

<p align="center">
  <img src="https://github.com/maltsevd/SpamKiller/assets/54685997/7f57a7e0-33b2-463c-baf6-7aad0a1ebe50" width=20%>
</p>

# **Problem Statement and Project Objectives**

Проблема спама в больших чатах является распространенной. Спам затрудняет общение между людьми, поиск нужной информации, что в конечном итоге может привести к тому, что люди начнут покидать чат, потому что находиться в нем будет невозможно из-за обилия спама.

Избавившись от спама в чате, мы сможем сделать общение между людьми более комфортным, потому что неприятно переписываться в чате или искать информацию и часто натыкаться на мошенническую информацию о скидках в размере 90%.

В целом, цель данного проекта - свести количество спама к минимуму, освободить администраторов от рутинного просмотра чата на предмет спама, круглосуточного мониторинга чата ботом, своевременного принятия решения о блокировке пользователя и удалении спама.

# Preliminary Research

В среднем спам-сообщение в чате появляеться 2-3 раза в день, максимальное зафиксированное 5 спам-сообщений в день.

Удаление спам-сообщений занимается два модератора.    

# Metrics & Losses

### Online-metrics

- ***Время реакции:** насколько быстро бот удаляет спам (хотим < 1 сек);*
- ***Recall:** какую долю спама удаляет (хотим > 95%);*
- ***Specificity:** ”true negative rate” (хотим > 99.9%).*

<p align="center">
<img src="https://github.com/maltsevd/SpamKiller/assets/54685997/01d0c470-4bcd-4274-b443-5b9247a77572" width=75%>
</p>

### Offline-metrics

- ***Recall @ Specificity > 99.9%:** доля верно детектированного спама при условии отсечки, дающей долю ложных срабатываний менее 1 на 1000.*
https://t.me/cryptovalerii/184
- ***ERR (Equal Error Rate):** как далеко точка ROC-кривой где FPR и FNR совпадают.*
https://hal.science/hal-00674526/document
- ***ROC-AUC:** площадь под ROC-кривой.*
https://en.wikipedia.org/wiki/Receiver_operating_characteristic
- ***PR-AUC:** площадь под Precision-Recall кривой.*
https://www.geeksforgeeks.org/precision-recall-curve-ml/

### Losses

- ***LogLoss:** метрика для оценки предсказанной вероятности что сообщение - спам.*

### **Technical**

- ***Latency (0.99 quantile):** скорость обработки сообщения в пессимистичном случае.*
- ***RAM (max):** максимум оперативной памяти, который занимает ML сервис.*
- ***QPS:** queries-per-second, сколько запросов в секунду обрабатывает бот.*

# **Data Collection**

Данные для обучающей модели были получены путем сбора спам-сообщений из целевого telegram-канала. Такой подход помог избежать расфокусировки данных и сосредоточился на типе спама, который чаще встречается в telegram-канале, для которого создается бот.

Сбор данных осуществляется "вручную", а именно:

- Примеры спам-сообщений собираются в отдельном telegram-канале с последующей выгрузкой и обработкой для отправки модели. Этим сообщениям будет присвоена метка 1 (положительный). Пример текстового сообщения, содержащего спам: "В связи со скандалом Всемирный банк решил извиниться перед клиентами и снизить цены. Не упустите шанс забрать любые вещи бесплатно - <ссылка на канал tg>"
• Примеры сообщений, не содержащих спама, собраны в файле .json. Этим сообщениям была присвоена метка 0 (отрицательная). Пример текстового сообщения, не содержащего спама: "для такой <ссылки> есть классная библиотека python".
- Есть автоматическая разметка уже со стороны работающего бота

Гарантия отсутствия спам-сообщений в данных с меткой 0 дает нам уверенность в том, что чат модерируется администратором, который удаляет спам, что с высокой степенью вероятности гарантирует, что спам был удален и не был загружен. Это относится к данным с меткой 1.
Все сообщения с метками 0 и 1 принимаются за один и тот же период времени – это гарантирует одинаковую пропорцию в данных.

## Features

В качестве фичей выступают на данный момент 13 правил:

1. **Проверка наличия ссылок Telegram**:
    - Только telegram ссылка в сообщении: +0.3
    - Много telegram ссылок в сообщении: +0.3
    - Одна telegram ссылка в сообщении: +0.15
2. **Проверка наличия стоп-слов**:
    - Наличие каждого стоп-слова: +0.30
3. **Проверка наличия опасных слов**:
    - Наличие каждого опасного слова: +0.15
4. **Проверка наличия спам-слов**:
    - Наличие каждого спам-слова: +0.5
5. **Проверка подмены кириллицы**:
    - Наличие подмены кириллицы: +0.1 за каждое слово
6. **Проверка наличия фотографии**:
    - Наличие фотографии в сообщении: +0.15
7. **Проверка идентификатора отправителя на отсутствие спама**:
    - Если **`from_id`** из списка не спам: -0.5
8. **Проверка наличия специальных символов**:
    - Наличие каждого неразрешенного символа: +0.1
9. **Проверка длины сообщения**:
    - Слишком короткое сообщение: +0.1
10. **Проверка наличия слов, недостаточно похожих на другие**:
    - Наличие каждого слова из списка слов, недостаточно похожих на другие слова: +0.15
11. **Проверка наличия заглавных букв**:
    - Большая концентрация заглавных букв: +0.15
12. **Проверка наличия подозрительных эмодзи**:
    - Наличие каждого подозрительного эмодзи: +0.15
13. **Проверка наличия ссылок**:
    - Только ссылка в сообщении: +0.3
    - Одна ссылка и текст в сообщении: +0.15
    - Несколько ссылок в сообщении: +0.3

Все баллы суммируются, а затем нормализуются по порогу в 1.0. Если сумма баллов равна или превышает порог, нормализованный балл устанавливается равным 1.0. Если сумма баллов меньше нуля, нормализованный балл устанавливается равным 0.0. В остальных случаях нормализованный балл равен сумме баллов, деленной на пороговое значение.

## Completeness and volume of data

Описанно в разделе **Error Analysis**, в подразделе **Оценка размера выборки**.

# Data storage

## Unprocessed data

Текстовые данные, загруженные из двух tg-чатов (первого, где мы собираем спам, и второго, где модератор регулярно очищает наши сообщения от спама), будут сохранены в формате .json.

## Processed data

Обработанные (очищенные) данные будут сохранены в таблицах csv.

## Cloud data storage

Данные будут храниться в таблицах формата .csv, а контроль версий будет осуществляться с помощью облачного хранилища и DVC (Data Version Control). Это обеспечит легкий доступ к данным и обмен ими между членами команды, а также обеспечит регистрацию изменений, вносимых в данные с течением времени.

# **Validation**

Валидация - важный шаг в разработке модели, позволяющий гарантировать, что модель хорошо работает с новыми, невидимыми данными. В нашем проекте мы внедрим схему проверки, в которой набор данных будет разделен на две части - обучающий набор и тестовый набор. На первом наборе данных мы обучим нашу модель, а на тестовом наборе оценим производительность нашей модели. Эти показатели помогут нам принимать решения о выборе модели и настройке параметров, а также помогут нам убедиться в том, что наша модель надежна и хорошо работает в реальных сценариях.

В обучающий набор попадет 80%, а в тестовый набор попадет 20% данных. На первой интерации проекта, мы будем обновлять данные раз в неделю.

## Learning Curve

Оценка размера выборки и изучение кривой обучения (Learning Curve) - это важные компоненты при проектировании и оценке моделей машинного обучения.

Для оптимальной оценки размера обучающей выборки нам необходимо построить Learning Curve.

Алгоритм анализа следующий

1. Выбрать метрику для оценки качества модели. 
2. Затем, разбить ваш набор данных на обучающую и тестовую выборку.
3. После этого, начинать обучать модель на различных подмножествах обучающей выборки. Например, сначала вы можете обучить модель только на 10% данных, затем на 20% и так далее, до 100%.
4. На каждом этапе, после обучения модели, вы можете проверить ее качество на тестовой выборке, используя выбранную метрику.
5. В результате, у нас получится набор пар значений: размер обучающей выборки и качество модели. Мы можем построить график зависимости этих значений, который и будет кривой обучения.

Если кривая обучения выходит на плато, это означает, что дальнейшее увеличение обучающих данных не приведет к значительному улучшению качества модели, и размер выборки можно считать оптимальным.

# **Baselines Models**

## **Список моделей**

Предлагается трехуровневая реализация с постепенным усложнением:

- модель основанная на эвристических правилах
- Логистическая регрессия/SVM с разными ядрами
- Изолированный лес
- AutoEncoder

## **Модель на эвристиках**

В качестве базовой версии, для последующего сравнения с более сложными вариантами, будет использоваться обычная модель на эвристиках.
Реализация представляет собой простой ряд бинарных вопросов. Как пример:

- в сообщении есть стоп-слова?
- были ли сообщения от этого пользователя раннее?
- сообщение содержит ссылку в домене Х?
- есть картинка в сообщении?
- доля слов на латинице и кириллице в сообщении больше X?
- время за которое пользователь оставил сообщение меньше X?

Потом эти ответы суммируются (с определённым весом) и делятся на общую сумму (для лучшей интерпретируемости). При прохождении первого порога отправляются администратору для дальнейшей классификации, при прохождении второго порога автоматически блокируются. Пороги определяются в соответствии с необходимыми результатами метрики качества.
Реализация представляется возможной из-за доминирования 3-4 классов спамов со своей спецификой и гомогенностью внутри себя.
Положительные качества модели на эвристиках:

- одна из самых быстрых скоростей работы
- масштабируемость
- интерпретируемость результата
- вопросы для классифицирования можно узнать у экспертов
- более сложные модели можно дополнять ответами базовой модели

Минусы:

- приходиться переписывать правила при появления новых классов, так и при изменении уже имеющихся
- не обнаруживает редкие проявления спама

## Логистическая регрессия/SVM

Обобщение модели, основанной на эвристических правилах. Плюс по возможности прикрутить простенький TF/IDF и посчитать метрики.

## **Изолированный лес**

Изолированный лес способен эффективно обнаруживать аномальные или необычные закономерности в данных, включая аномалии, связанные с мошенничеством. Алгоритм строит деревья решений, разделяя данные на разные ветви, пока каждый экземпляр не будет полностью изолирован. Аномальные точки обычно требуют меньшего количества разделений, чтобы изолировать их, поэтому они имеют более короткую длину пути в дереве.

Признаки которые мы будем использовать:

- эмбеддинги слов. Нейронной сетью, которая будет обрабатывать текстовые сообщения (токенизировать), будет переобученный RuBert на наших данных. RuBert лучше всего подходит для нашей задачи, так как нам важно сохранить контекст сообщения, а не только частотность и важность слова, как это было бы, когда мы использовали TF–IDF
- ответы rule-based модели

Главным плюсом этой реализации, является обнаружение редких спамов по их аномальной непохожести. Минусом является сложность в реализации. Также стоит отметить ожидаемую прибавку в качестве в целом по сравнению с прошлыми моделями.

# **Error Analysis**

## **Оценка размера выборки**

Для примерной оценки размера выборки мы можем построить график зависимости ошибки от нашей выборки. Зная необходимый уровень качества, и имея не большое количество выборок разных размеров, мы можем аппроксимировать имеющиеся данные и найти необходимый размер с приемлемым уровнем качества.

<p align="center">
<img src="https://github.com/maltsevd/SpamKiller/assets/54685997/03c4dae4-9c25-4457-b972-a28ad120a5d1">
</p>

## **Проверка модели на переобучение/недообучение**

Будет проходить с использованием классического графика сложности модели (числа итераций) от результата на test и train

<p align="center">
<img src="https://github.com/maltsevd/SpamKiller/assets/54685997/11247a97-c2f3-4544-bc59-b7279c471883">
</p>

## **Проверка модели на сходимость/расходимость**

Используется для итерактивных моделей. Строим график уменьшения ошибки от времени (числа итераций) при этом учитываем возможность переобучения модели. Другим вариантом является график размера обучающего шага от времени (числа итераций).

<p align="center">
<img src="https://github.com/maltsevd/SpamKiller/assets/54685997/fd925038-e49b-4d22-aca6-80af3cd2ea9d">
</p>

## **Проверка модели на оптимальную сложность/глубину**

Помимо проверки на переобучение, подразумевает простой график уменьшение ошибки от сложности модели. В какой-то момент ожидается выход графика на плато, при котором дальнейшее увеличение сложности модели, а следствие более медленная работа, не будет компенсироваться уменьшением ошибки.

<p align="center">
<img src="https://github.com/maltsevd/SpamKiller/assets/54685997/19b0cb37-cb85-4f36-b0ac-3666e6062935">
</p>

## **Остатки**

Для нашей задачи бинарной классификации, остатками будут являться разницы истиной вероятности класса 1 и предсказанной.

## **Проверяем распределения ошибок для первого и второго класса**

Распределение должно стремить к нормальному. При равномерном распределении мы одинаково плохо предсказываем реальные данные. Если существует смещение модели можно посмотреть в сторону увеличения данных или их перебалансировки, а также усложнения модели. Если сложное распределение возможно есть паттерн, который наша модель не может уловить.

## **Анализ паттерна ошибок**

Будет проходить с использованием аналитических методов. Таких как: визуализация, кластеризации, поиск корреляций.

## **Включение ошибок в пайплайн обучения**

При обнаружения частых ошибок, поддающихся объяснению, модель должна быть переобучена с изменением количества данных и их качественного содержания.

# **Training Pipeline**

## **Модель на эвристиках**

Собираем корпус текстов чата КК. На основе его анализа и при помощи логики составляем правила, по которым будет работать наша модель. Также с пополнением правил могут помочь эксперты по блокировки спама.

Проводим валидацию на отложенной выборки. В конце сохраняем артефакты (метрики, лосс-кривые, сложные случаи для классификации).

<p align="center">
<img src="https://github.com/maltsevd/SpamKiller/assets/54685997/0a977dd5-25f5-42be-87d0-d47535373c3b">
</p>

## Логистическая регрессия/SVM

Для начала обучить модель на наших эвристических правилах и измерить качество. 

Далее: 

Для обучения будет создана матрица слов в корпусе текстов чата КК. Мы избавимся от ненужных символов (смайликов и т.п.), приведем все слова к нижнему регистру, заменить цифры в тексте лексемой <NUMER>.

Для того чтобы нормировать матрицу будет применено tf-idf преобразование, что позволить не обращать внимание на маловажные слова. Для целей облегчения предсказания, мы уменьшим размерность имеющейся матрицы

На полученной матрице будет обучен линрег/SVM, с последующей валидацией на отложенных данных.

В конце подразумевается сбор артефактов (метрики, лосс-кривые, сложные случаи для классификации).

<p align="center">
<img src="https://github.com/maltsevd/SpamKiller/assets/54685997/c415b1e6-fcf8-4e8a-ae9d-13b896812fcd">
</p>

## **Изолированный лес**

Загружаем корпус текстов чата КК. Избавимся от ненужных символов (смайликов и т.п.), приведем все слова к нижнему регистру, заменить цифры в тексте лексемой <NUMER>.

С помощью нейронной сети RuBert мы представим наши тексты в сжатое представление хорошо отражающее нашу задачу.

К обучающему датасету мы так же добавим ответы нашей rule-based модели.

Обучаем изолированный лес и проводим валидацию. В конце подразумевается сбор артефактов (метрики, лосс-кривые, сложные случаи для классификации).

<p align="center">
<img src="https://github.com/maltsevd/SpamKiller/assets/54685997/3e3e0ba5-fd01-4105-83b0-b656f022e876">
</p>

# **Inference Pipeline**

Письменное сообщение отправляется боту.  В зависимости от выбранной модели, бот либо сразу отправляет данные ей (модель первого порядка), либо предварительно обрабатывает данные (модели второго и третьего порядка). Основываясь на прогнозе, бот может совершить три действия:

- заблокировать пользователя
- отправить экспертам (при сомнении в классификации)
- игнорировать сообщение

<p align="center">
<img src="https://github.com/maltsevd/SpamKiller/assets/54685997/b090a69e-fe73-4549-bd22-81e370722b49">
</p>

# **Integration and Deployment**

Важным этапом в разработке бота является его дальнейшее использование конечными пользователями – администраторами чата.
Весь проект будет упакован в Docker с возможностью замены токенов.

Далее бот будет развернут на VPS-сервере.

# Protection from unfair (erroneous) ban

Этот вопрос чрезвычайно актуален, поскольку в машинном обучении мы работаем с вероятностями, и вероятность несправедливого (ошибочного) бана не равна нулю, то мы должны это учитывать и не давать боту абсолютных прав банить пользователей. Если мы не примем во внимание этот важнейший фактор, то, выпустив в производство бота, обладающего абсолютной властью, мы можем столкнуться с тем, что бота могут начать несправедливо банить, что негативно скажется на репутации конечного продукта.

1. В течение первых n недель бан не вводится. Если бот видит спам, он отправляет это сообщение администратору, и он уже определяет "удалить/не удалять".
2. Если работа бота устраивает администратора чата (нет или минимальное количество несправедливых банов), то вводится правило: пауза между выдачей банов + если банов > 5 за 5 минут, то бот выключается на час и сообщает об этом администратору.

# What's done?

На момент времени 01.10.23 было сделано:

- Бот работает в чатах [Karpov.courses](http://Karpov.courses)/Время Валеры/BOGDANISSIMO/Dimension. Более 35, 000 пользователей
- Очистка .json файла с историей сообщений из чата КК и образцов спама, и упаковка в причесанные датафреймы.
- Настроен мониторинг: верификация экспертов, деления сообщений на Spam/not SPAM
- Модель на правилах.
- Замеры метрик.

Чтобы запустить бота вам нужно создать токен, вставить его в .env, чтобы вам начали приходить уведомления о спаме, вам нужно добавить свой id в .env
